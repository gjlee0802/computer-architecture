# 면접 기출 예시

## 개념 질문
### Memory Hierarchy
#### 1. ❓캐시가 필요한 이유는? Cache hit ratio 에 대해 설명하시오.
* 캐시가 필요한 이유: 
~~~
캐시는 데이터 접근 속도를 높이고, 시스템의 성능을 최적화하기 위해 사용
즉, 빠른 메모리에 자주 사용하는 데이터를 저장해서 성능을 높이자는 원칙
~~~
* Cache hit ratio란?:
~~~
Cache Hit Ratio(캐시 적중률)는 캐시에서 원하는 데이터를 찾을 확률을 나타내는 지표로, 전체 요청 중 캐시에서 성공적으로 제공된 요청의 비율을 의미함

Cache Hit Ratio = Cache Hits / (Cache Hits + Cache Misses)
~~~

#### 2. ❓메모리 접근하는데 x 사이클이 걸리고 캐시에 접근하는데 y 사이클이 걸리며 캐시 hit rate 가 h %일 때 effective access time은?
~~~
EAT (Effective Access Time)은 cache를 활용한 메모리 접근의 평균 소요 시간을 계산하는 값
~~~
~~~
Cache Hit rate와 Miss rate를 고려하여 다음과 같이 계산함:

EAT = (Hit Rate x Cache Access Time) + (Miss Rate x (Cache Access Time + Memory Access Time))-
    = Cache Access Time + Miss Rate x Memory Access Time
~~~
🎯 즉, `캐시 접근 시간 y`에 `Cache Miss 발생 시 추가로 걸리는 메모리 접근 시간`이 더해지는 형태!  

#### 3. ❓Page Fault는 언제 발생하는가? Page Fault 비율과 Cache Miss 비율 중 큰 것은? 그 이유는?
**Page Fault는 언제 발생하는가?:**
~~~
🎯 Page Fault는 Page Table에서 해당 페이지의 Valid Bit이 0으로 설정되어 있어, 해당 페이지가 물리 메모리에 존재하지 않는 경우 발생함  
✅ 이때 운영체제(OS)는 디스크에서 해당 페이지를 가져와 메모리에 로드하는 과정(Page Swap-In)을 수행함  
~~~
**Page Fault 비율과 Cache Miss 비율 중 큰 것은? 그 이유는?:**
~~~
🎯 일반적으로 Cache Miss 비율이 Page Fault 비율보다 훨씬 큼  
✅ 이유: 캐시는 작은 용량에서 빠르게 동작하며 자주 교체되지만, 페이지는 운영체제가 효율적으로 관리하여 디스크 접근을 최소화하기 때문  
~~~

#### 4. ❓Cache Miss의 3 종류 (3C)를 나열하고 각각에 대해 Miss를 낮추는 방법을 설명하시오.
~~~
1️⃣ Conflict Misses (충돌 미스): 
    ✅ 원인: Set 내부에서의 Cache Entry끼리 경쟁으로 발생
    ✅ 감소 방법: Fully Associative (Associative, Set의 개수 증가)

2️⃣ Compulsory(aka. Cold Start) Misses (필수 미스): 
    ✅ 원인: Block에 처음 접근할 때는 비어있어, Miss가 필수적으로 발생
    ✅ 감소 방법: Block의 크기 증가

3️⃣ Capacity Misses (용량 미스): 
    ✅ 원인: 캐시 크기(용량)가 부족해서 기존의 Block이 강제로 제거됨
    ✅ 감소 방법: 캐시 크기 증가
~~~

### Virtual Memory
#### 1. ❓캐시 메모리와 메인 메모리의 주소 지정 방식의 차이점이 무엇인가?
~~~
🎯 캐시는 CPU가 메모리에 접근할 때 Physical Address를 기반으로 접근하도록 함
    반면, 프로세스가 사용하는 메인 메모리는 Virtual Address를 기반으로 접근 (OS가 Virtual Address를 Physical Address로 매핑하여 메인메모리를 관리)
~~~
#### 2. ❓TLB란 무엇인가?
~~~
TLB: Virtual Address를 Physical Address로 변환할 때 사용하는 Cache 장치로, 매번 메인메모리의 Page Table을 탐색하지 않아도 되도록 하기 위해 최근에 Translation에 사용한 주소 Mapping 정보를 보관함
~~~

## Cache Performance 관련 심층 문제
### 1. ❓Level 1 Cache(Primary Cache)가 아래와 같은 Miss Rate로 동작한다고 하자. Miss rate = 0%인 Perfect cache가 있다고 가정할 때, 아래의 Cache 대비 성능 향상 Factor을 계산하시오. (SSU 17년도 기출)
**주어진 Cache의 변수:**
~~~
Instruction cache miss rate = 2%
Data cache miss rate = 4%
CPI = 1 without any memory stalls
Miss penalty = 100 cycles
Frequency of all loads and stores = 25%
~~~

**Actual CPI 계산:**
~~~
Base CPI = 1
I-Cache Miss Cycle = Instruction Cache Miss Rate x Miss Penalty = 0.02 x 100 = 2 Cycle
D-Cache Miss Cycle = Data Cache Miss Rate x 0.25 x Miss Penalty = 0.04 x 0.25 x 100 = 1 Cycle
Actual CPI = Base CPI + I-Cache Miss Cycle + D-Cache Miss Cycle = 1 + 2 + 1 = 4 Cycle
~~~
따라서 Perfect Cache는 위의 Cache 성능(Actual CPI)에 비해 4배의 성능 향상이 있음

-----

### 2. ❓Multilevel Cache 성능 비교이다. (SSU 17년도 기출)

**(a) 주어진 Level-1 Cache(Primary Cache)의 변수:**
~~~
Clock rate = 4 GHz
CPI = 1.0 with a primary cache of 100% hit rate
Main memory access time = 100 ns (including miss handling)
Miss rate/instruction at the primary cache = 2 %
~~~

**(b) 주어진 Level-2 Cache의 변수:**
~~~
Miss rate (to Main Memory) = 0.6 %
L2 cache access time = 5 ns
~~~

#### 2.1. ❓Primary cache(L1 cache)만을 사용할 경우 Total CPI(Effective CPI)를 구하시오. 
🎯 `Total CPI` = `Base CPI` + `Miss CPI` = `Base CPI` + (`Miss Rate/Instruction` x `Miss Penalty`)  
✅ 여기서는 Miss Penalty를 계산하는 것이 중요 Point!  
✅ `L1 Cache Miss Penalty` = `Memory Access Time` / `Clock Cycle Time`  

✅ **풀이:**  
~~~
Base CPI = 1
Clock rate = 4GHz가 주어지면,  =>  1 Clock cycle 소요 시간 계산 떠올리기
1 Clock cycle time = 1 / Clock rate = 1 / 4GHz = 0.25 ns
L1 cache Miss penalty = Memory Access Time / Clock Cycle Time = 100 ns / 0.25 ns = 400 Clock cycles
~~~
🎯 따라서 Total CPI(Effective CPI)는 아래와 같이 계산됨
~~~
Total CPI = 1 + (0.02 x 400) = 1 + 8 = 9 Clock cycles
~~~

#### 2.2. ❓L2 cache까지 사용할 경우 Total CPI(Effective CPI)를 구하시오.
🎯 `Total CPI` = `Base CPI` + `L1 Miss with L2 Hit CPI` + `L1 Miss with L2 Miss CPI`  
✅ 여기서는 L2 Cache에서 Hit일 때와 Miss일 경우의 L1 Miss CPI를 나누어 생각하는 것이 중요 Point!  
✅ Primary Stalls: `L1 Miss with L2 Hit CPI` = `Miss rate at the primary cache` x `L1 Miss with L2 Hit Penalty`  
✅ Secondary Stalls: `L1 Miss with L2 Miss CPI` = `L2 Miss rate (to Main Memory)` x `L1 Miss with L2 Miss Penalty`  

✅ **풀이:**  
~~~
1 Clock cycle time = 1 / Clock rate = 1 / 4GHz = 0.25 ns

(1). L1 Miss with L2 Hit Penalty 계산하기 (L2 Access에 대한 Penalty 계산)
L1 Miss with L2 Hit Penalty = L2 cache access time / Clock cycle time
    = 5 / 0.25 = 20 Clock cycles

(2). L1 Miss with L2 Miss Penalty 계산하기 (Main Memory Access에 대한 Penalty 계산)
L1 Miss with L2 Miss Penalty = Memory access time / Clock cycle time
    = 100 / 0.25 = 400 Clock cycles
~~~
🎯 따라서 Total CPI(Effective CPI)는 아래와 같이 계산됨  
~~~
Total CPI = Base CPI + Primary Stalls + Secondary Stalls
    = 1 + (2% x 20) + (0.6% x 400) = 3.8 Clock cycles
~~~

#### 2.3. ❓L2 cache까지 사용할 경우, L1 cache만을 사용할 경우 대비 성능 향상 Factor을 계산하시오.
🎯 Primary cache만을 사용할 경우에는 Total CPI가 9, L-2 cache까지 사용할 경우 Total CPI가 3.8이었으므로, 2.36배의 성능 향상을 보임  
~~~
9 / 3.8 = 2.36
~~~

-----

### 3. ❓TLB, Cache, Virtual Memory를 통합하여 사용한다고 하자. 그림은 CPU가 Virtual Address로 Memory Access를 요청했을 경우 처리되는 경우들을 나누어 보여준다. (SSU 19년도 기출)
![cache_tlb_virtualmem](../image_files/cache_tlb_virtualmem.jpg)  

#### ❓3.1. (E), (F), (I)의 Box 안 내용은 각각 무엇인가?
~~~
* (E): Lookup Page Table
* (F): Page Fault
* (I): Page Fault Exception => Page Fault Handler
~~~

#### ❓3.2. 실제 Physical Address로 Translation이 이루어지는 구간들은 어디인가? (예시: A와 B 사이 구간)
🎯 Cache에 접근하게 되는 구간에서 Virtual Address => Physical Address의 Translation이 이루어짐  
~~~
* B와 C 사이 구간
* F와 G 사이 구간
~~~
#### ❓3.3. TLB Access Time = 10ns, Cache Access Time = 20ns, Main Memory Access Time = 100ns라고 하자.

**3.3.1. 그림 하단의 (0) ~ (3) 각각에 대해 메모리 접근 시간을 계산하시오.**
~~~
* (0): 10 + 20 = 30 ns
* (1): 10 + 20 + 100 = 130 ns
* (2): 10 + 100 + 20 = 130 ns
* (3): 10 + 100 + 20 + 100 = 230 ns
~~~

❓**3.3.2. TLB Hit Rate = 99%, Cache Hit Rate = 80%라고 하자. 그림 하단의 (4)는 발생하지 않는다고 가정한다. CPU의 평균 메모리 접근시간을 위 3.3.1. 문제의 결과들을 이용하여 계산하시오. 메모리 참조 전체를 1로 간주할 때, (0) ~ (3) 각각이 차지하는 비율이 얼마인지를 먼저 계산하시오.**

**(0) ~ (3) 각각이 차지하는 비율 계산:** 
~~~
* (0): TLB Hit Rate x Cache Hit Rate = 0.99 x 0.8 = 0.79
* (1): TLB Hit Rate x Cache Miss Rate x 1 = 0.99 x 0.2 = 0.19
* (2): TLB Miss Rate x 1 x Cache Hit Rate = 0.01 x 0.8 = 0.008
* (3): TLB Miss Rate x 1 x Cache Miss Rate x 1 = 0.01 x 0.2 = 0.002
~~~

평균 메모리 접근 시간 계산:
~~~
(0)이 차지하는 비율 x (0)의 메모리 접근 시간 + (1)이 차지하는 비율 x (1)의 메모리 접근 시간 + (2)이 차지하는 비율 x (2)의 메모리 접근 시간 + (3)이 차지하는 비율 x (3)의 메모리 접근 시간

= (0.79 x 30) + (0.19 x 130) + (0.008 x 130) + (0.002 x 230) = 51 ns
~~~

-----

### 4. ❓아래의 설정 중, 어떤 것이 더 낮은 AMAT(Average Memory Access Time)을 갖고 있는가? 이유를 함께 설명하시오. (POSTECH 24-25 Second)
~~~
(1) A 32kB L1 cache, hit time of 1 cycle and miss time of 5 cycles, accessing a 256kB L2 cache. The L1 hit rate is 70% and the L2 hit rate is 100%

(2) A 64kB L1 cache, hit time of 2 cycles and miss time of 4 cycles, accessing a 128kB L2 cache. The L1 hit rate is 90% and the L2 hit rate is 100%
~~~

✅ **풀이:**

(1)의 AMAT부터 계산해보자.
~~~
L2 hit rate가 100%이므로, L2 miss는 고려하지 않음
L1 hit rate가 70%이므로, L1 miss rate는 30%임

AMAT = L1 hit time + L1 miss rate x L1 miss pentalty
     = 1 + 0.3 x 5
     = 2.5 cycles
~~~
(2)의 AMAT를 계산해보자.
~~~
L2 hit rate가 100%이므로, L2 miss rate는 고려하지 않음
L1 hit rate가 90%이므로, L1 miss rate는 10%임

AMAT = L1 hit time + L1 miss rate x L1 miss penalty
     = 2 + 0.1 x 4
     = 2.4 Cycles
~~~
  
결론적으로,  
~~~
🎯 (2)의 (1)보다 더 낮은 AMAT를 갖고 있다.  
추가적으로, 캐시 용량은 AMAT 계산에는 직접적으로 영향을 주지 않지만,  
용량이 커지면, 대체로 Hit rate가 증가하고 Miss rate가 감소하는 경향이 있다.  
~~~
-----

### 5. ❓프로그램이 실행 사이클의 50%를 연산(Computation)에, 나머지 50%를 메모리 계층(Memory Hierarchy)을 통한 데이터 I/O에 사용한다고 가정하자. 시스템은 2단계 캐시 계층 구조(Two-level cache hierarchy)를 가지고 있으며, L1 캐시는 4사이클의 지연 시간(latency)과 10%의 미스율(miss rate)을 가진다. 마찬가지로, L2 캐시는 20사이클의 지연 시간과 20%의 미스율을 가지며, DRAM 접근은 평균적으로 100사이클이 소요된다.  (POSTECH 22-23 Second)

#### 5.1. ❓AMAT(Average Memory Access Time)은 몇 사이클인가?
✅ **AMAT 계산 공식(L2 miss를 고려한 일반식)**:  
~~~
AMAT = L1 hit time + L1 miss rate x (L2 hit time + L2 miss rate x Main Memory Access Time)
~~~

✅ 위에서 주어진 변수들을 정리해보면,  
* L1 Cache
    * Hit time: 4 cycles
    * Miss rate: 10 %
* L2 Cache
    * Hit time: 20 cycles
    * Miss rate: 20 %
* Main memory
    * Access time: 100 cycles

🎯 AMAT를 계산해보면,  
~~~
AMAT = 4 + 0.1 x (20 + 0.2 x 100) = 8 cycles
~~~

✅ "50% 연산 + 50% 메모리 I/O"는 AMAT 계산 자체에는 사용되지 않음, 그러나 AMAT 개선이 전체 성능 향상에 끼치는 영향을 분석하는 데 꼭 필요함

#### 5.2. ❓동일한 비용 예산 내에서 전체 성능을 향상시키기 위해 다음 세 가지 후보 중 하나를 선택할 수 있다. 가장 빠른 시스템을 만들기 위해 어떤 옵션을 선택해야 하는가?
~~~
Option 1. 연산에 소요되는 실행 사이클을 20% 줄일 수 있도록 컴퓨팅 코어를 업그레이드한다.
Option 2. L1 캐시에 프리페처(prefetcher)를 도입하여 L1 및 L2 캐시의 미스율을 절반으로 줄인다.
Option 3. 평균 접근 지연 시간이 60사이클로 더 빠른 DRAM을 도입한다.
~~~

✅ **기준선: 기존 시스템의 전체 실행 시간**:
* 전체 실행 시간 = 연산 시간 + 메모리 I/O 시간
* 연산: 50%
* 메모리 I/O: 50%
* AMAT: 8 cycles

따라서, **전체 실행 시간 기준을** `100 cycles`이라고 **가정한다면**,
* 연산: 100 x 0.5 = 50 cycles
* 메모리: 100 x 0.5 x AMAT = 50 x 8 = 400 cycles
* 연산 + 메모리: 50 + 400 = 450 cycles

✅ Option 1에 대한 성능 향상 계산
* 연산: 50 x 0.8 = 40 cycles
* 메모리: 400 cycles
* 연산 + 메모리: 40 + 400 = **440 cycles**

✅ Option 2에 대한 성능 향상 계산
* 캐시 Miss rate가 달라졌으므로 AMAT를 다시 계산하면,
    ~~~
    AMAT = 4 + 0.05 x (20 + 0.1 x 100) = 4 + 0.05 x 30 = 5.5 cycles
    ~~~
* 연산: 50 cycles
* 메모리: 100 x 0.5 x AMAT = 50 x 5.5 = 275 cycles
* 연산 + 메모리: 50 + 275 = **325 cycles**

✅ Option 3에 대한 성능 향상 계산
* Memory Access Time이 달라졌으므로 AMAT를 다시 계산하면,
    ~~~
    AMAT = 4 + 0.1 x (20 + 0.2 x 60) = 4 + 0.1 x 32 = 7.2 cycles
    ~~~
* 연산: 50 cycles
* 메모리: 100 x 0.5 x AMAT = 50 x 7.2 = 360 cycles
* 연산 + 메모리: 50 + 360 = **410 cycles**

🎯 결론적으로, 
~~~
Option 2을 선택해야 한다.
~~~

## Cache Associative 관련 심층 문제
### 1. ❓그림은 4 way set associative 방식 cache memory 구조를 보여준다. 각 data 크기는 4 byte이다. (SSU 18년도 기출)
![4-way_set_associative_cache](../image_files/4-way_set_associative_cache.png)  
#### 1.1. ❓그림에서 맨위 Address가 주어졌을 때, cache hit인지 판단하는 과정, hit일 경우 최종 data를 읽어내는 과정을 설명하시오.
1️⃣ **Step 1. 주소 분해** (Address Breakdown)
* 주어진 32-bit 주소에서:
    * Tag (22-bit): 상위 22비트
    * Index (8-bit): 중간 8비트 (256개의 index)
    * Offset (2-bit): 하위 2비트 (4-byte 데이터)

2️⃣ **Step 2. Index로 Cache 조회**
* Index 필드를 사용하여 해당 Index의 4개(4-way) 캐시 블록을 모두 조회
    * Index 하나당 4개의 캐시 블록이 조회됨

3️⃣ **Step 3. Tag 비교 및 유효성 체크**
* 각 way에서 저장된 Tag와 입력 Tag를 비교하고, Valid Bit가 1인지 확인
* 일치하는 Tag가 있고, 동시에 Valid Bit가 1이면 Cache Hit

4️⃣ **Step 4. Multiplexer을 통한 데이터 선택**
* Hit이 발생한 way의 데이터를 4-to-1 멀티플렉서를 사용하여 선택함
* 선택된 4 byte 데이터를 출력함

5️⃣ **Step 5. Hit 신호 출력**

#### 1.2. ❓data 부분의 cache memory의 총 크기는? (byte 단위로 표기할 것)
~~~
4 x 256 x 4 = 4096 bytes
~~~
#### 1.3. ❓data 부분의 cache memory의 총 크기는 위의 1.2.와 동일하고, 16 way set associative 방식으로 변경되어 운영한다고 하자. 맨 위에 주어진 실제 메모리 주소는 tag, index, block 내부 offset(B) (또는 block 내부 offset(W) 및 Word 내부 byte offset)으로 나뉜다. 각각 몇 bit인가?
**Step 1. Index의 크기(bits) 계산을 위해 Set의 개수 구하기**:
~~~
16 way set associative 방식은 한 Set 당 블록의 개수가 16개라는 의미

Data 부분의 총 크기 = 4096 bytes
Block(= Data 1개)의 크기 = 4 bytes

블록(aka. Cache Entry)의 개수 = 4096 / 4 = 1024 개

Set의 개수 = 블록(= Cache Entry) 개수 / Way 수
    = 1024 / 16 = 64개
~~~
**Step 2. Tag, Index, Block 내 Offset의 크기 계산하기**:
~~~
Index 크기 계산: 
2^6 = 64 (= Set의 개수)이므로, Index는 모든 Set의 개수를 포함할 수 있는 6 bits로 이루어짐

Byte 내 Offset 크기 계산: 
Byte Offset은 Block의 크기가 4 bytes이므로 2 bits로 이루어짐

Tag 크기 계산: 
Tag는 전체 32 bits에서 Index, Bytes Offset 부분을 제외한 24 bits로 이루어짐
~~~

#### 1.4. ❓그림은 CAM 에 해당하는가? CAM의 정의도 함께 설명하시오.
~~~
그림은 CAM에 해당한다.

CAM이란?:
Content Addressable Memory의 약자, 메모리 접근 시 주소를 갖고 탐색하는 것이 아니라 메모리에 저장된 내용으로 탐색 (비트 단위로 데이터를 저장하고, 입력된 키와 비교하여 일치하는 주소를 반환)

CAM은 Associative Memory의 한 형태이며, 하드웨어적으로 병렬 검색을 최적화한 버전이다.
~~~

-----

### 2. ❓64-byte 캐시가 주어졌다고 하자. 8-byte words의 데이터를 저장하려고 한다.
#### 2.1. ❓얼만큼의 word를 저장할 수 있는가?
~~~
64 / 8 = 8 words
~~~

#### 2.2. ❓이러한 words를 구분하고 접근하기 위해 얼만큼의 bits가 필요한가? 
캐시에 저장된 각 word를 구분하고 접근하기 위해 사용되므로, **Index bits에 해당**
~~~
2^3 = 8 이므로, 
words의 주소를 구분하기 위해 3 bits가 필요함
~~~

#### 2.3. ❓각 word 내 byte에 접근하기 위해 얼만큼의 bits가 필요한가?
word 내에서 특정 byte를 선택하기 위한 것이므로 **Offset bits에 해당**
~~~
각 word는 8 bytes를 갖기 때문에,
word 내 각 byte에 접근하기 위해 3 bits가 더 필요함
~~~

